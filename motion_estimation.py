import os
import math
import time
import numpy as np
import pandas as pd
import nibabel as nib
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchdiffeq import odeint
from skimage import measure
import trimesh
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.utils import shuffle
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

from dataloader import CTSequenceDataset

# =========================================================
# 1. Mesh + Volume Utilities
# =========================================================
def compute_mesh_volume(vertices, faces):
    mesh = trimesh.Trimesh(vertices=vertices, faces=faces, process=False)
    return abs(mesh.volume)

def compute_frame_volume_gt(frame, voxel_spacing, level=0.5):
    verts, faces, _, _ = measure.marching_cubes(frame, level=level, spacing=voxel_spacing)
    return abs(compute_mesh_volume(verts, faces))

# =========================================================
# 2. SIREN Velocity Model
# =========================================================
class SineActivation(nn.Module):
    def __init__(self, w0=30.0):
        super().__init__()
        self.w0 = w0
    def forward(self, x):
        return torch.sin(self.w0 * x)

def encode_time(t):
    theta = 2 * math.pi * t
    return torch.stack([torch.cos(theta), torch.sin(theta)], dim=-1)

class SIRENVelocityField(nn.Module):
    def __init__(self, hidden_dim=256, num_layers=3, w0=30.0):
        super().__init__()
        self.w0 = w0
        layers = []
        in_dim = 5  # x,y,z + cos t + sin t
        layers.append(nn.Linear(in_dim, hidden_dim))
        layers.append(SineActivation(w0=w0))
        for _ in range(num_layers-1):
            layers.append(nn.Linear(hidden_dim, hidden_dim))
            layers.append(SineActivation(w0=w0))
        layers.append(nn.Linear(hidden_dim, 3))
        self.model = nn.Sequential(*layers)
        self._initialize_weights()

    def _initialize_weights(self):
        with torch.no_grad():
            first = True
            for layer in self.model:
                if isinstance(layer, nn.Linear):
                    if first:
                        bound = 1 / layer.in_features
                        layer.weight.uniform_(-bound, bound)
                        first = False
                    else:
                        bound = math.sqrt(6 / layer.in_features) / self.w0
                        layer.weight.uniform_(-bound, bound)

    def forward(self, coords, t):
        t_enc = encode_time(t)
        if t_enc.dim() == 1:
            t_enc = t_enc.unsqueeze(0)
        if coords.shape[0] != t_enc.shape[0]:
            t_enc = t_enc.expand(coords.shape[0], -1)
        return self.model(torch.cat([coords, t_enc], dim=-1))

# =========================================================
# 3. ODE Integration
# =========================================================
class VelocityFieldODE(nn.Module):
    def __init__(self, siren_model):
        super().__init__()
        self.siren = siren_model
    def forward(self, t, phi):
        t_full = torch.full((phi.shape[0],), t, device=phi.device)
        return self.siren(phi, t_full)

def integrate_velocity_to_deformation(siren_model, points, time_points, method='rk4'):
    ode_func = VelocityFieldODE(siren_model)
    trajectories = odeint(ode_func, points, time_points, method=method)
    return torch.clamp(trajectories, -1.0, 1.0)

# =========================================================
# 4. Intensity Sampling
# =========================================================
def sample_intensity(volume, coords):
    """
    Sample intensity values from a 3D volume using grid coordinates.
    
    Args:
        volume: 3D tensor of shape (C, H, W, D) or (H, W, D)
        coords: 2D tensor of shape (N, 3) with normalized coordinates in [-1, 1]
    
    Returns:
        1D tensor of sampled intensities
    """
    # Ensure volume has batch and channel dimensions
    if volume.dim() == 3:
        volume = volume.unsqueeze(0)  # Add batch dimension
    if volume.dim() == 4:
        volume = volume.unsqueeze(0)  # Add channel dimension if needed
    
    # Ensure coords are in the correct format for grid_sample
    # grid_sample expects coordinates in (x, y, z) format
    if coords.shape[-1] != 3:
        raise ValueError(f"Expected 3D coordinates, got shape {coords.shape}")
    
    # Reshape coords for grid_sample: (N, 3) -> (1, N, 1, 1, 3)
    coords = coords.view(1, -1, 1, 1, 3)
    
    # grid_sample expects coordinates in [-1, 1] range
    sampled = F.grid_sample(volume, coords, align_corners=True, mode='bilinear', padding_mode='border')
    return sampled.view(-1)

# =========================================================
# 5. Volume Plotting (CSV + Plot) with sklearn metrics
# =========================================================
def plot_and_save_volumes(gt_volumes, pred_volumes, save_path):
    frames_idx = np.arange(len(gt_volumes))
    
    # Calculate sklearn-based metrics
    mse = mean_squared_error(gt_volumes, pred_volumes)
    mae = mean_absolute_error(gt_volumes, pred_volumes)
    r2 = r2_score(gt_volumes, pred_volumes)
    
    # Calculate relative errors
    volume_diff_mm3 = np.array(pred_volumes) - np.array(gt_volumes)
    volume_diff_percent = (volume_diff_mm3 / np.array(gt_volumes)) * 100
    
    volume_data = pd.DataFrame({
        'frame': frames_idx,
        'time_phase': frames_idx / (len(gt_volumes)-1),
        'gt_volume_mm3': gt_volumes,
        'predicted_volume_mm3': pred_volumes,
        'volume_diff_mm3': volume_diff_mm3,
        'volume_diff_percent': volume_diff_percent
    })
    
    # Add summary statistics
    stats_summary = pd.DataFrame({
        'metric': ['MSE', 'MAE', 'RÂ²', 'Mean_GT_Volume', 'Mean_Pred_Volume', 
                   'Std_GT_Volume', 'Std_Pred_Volume', 'Mean_Abs_Error_%', 'Max_Abs_Error_%'],
        'value': [mse, mae, r2, np.mean(gt_volumes), np.mean(pred_volumes),
                 np.std(gt_volumes), np.std(pred_volumes), 
                 np.mean(np.abs(volume_diff_percent)), np.max(np.abs(volume_diff_percent))]
    })
    
    csv_path = save_path.replace('.png', '.csv')
    stats_csv_path = save_path.replace('.png', '_stats.csv')
    
    volume_data.to_csv(csv_path, index=False, float_format='%.3f')
    stats_summary.to_csv(stats_csv_path, index=False, float_format='%.6f')
    
    print(f"[INFO] Saved volume CSV to {csv_path}")
    print(f"[INFO] Saved statistics CSV to {stats_csv_path}")
    print(f"[INFO] Volume prediction metrics: MSE={mse:.3f}, MAE={mae:.3f}, RÂ²={r2:.6f}")

    plt.figure(figsize=(12, 8))
    
    # Main plot
    plt.subplot(2, 2, 1)
    plt.plot(frames_idx, gt_volumes, 'o-', label='Reference', color='orange', linewidth=2)
    plt.plot(frames_idx, pred_volumes, 'o-', label='Predicted', color='blue', linewidth=2)
    plt.xlabel("Frame")
    plt.ylabel("Volume (mmÂ³)")
    plt.title(f"Volume Comparison (RÂ²={r2:.3f})")
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Error plot
    plt.subplot(2, 2, 2)
    plt.plot(frames_idx, volume_diff_percent, 'ro-', linewidth=2)
    plt.xlabel("Frame")
    plt.ylabel("Error (%)")
    plt.title(f"Relative Error (MAE={mae:.3f}mmÂ³)")
    plt.grid(True, alpha=0.3)
    plt.axhline(y=0, color='k', linestyle='--', alpha=0.5)
    
    # Scatter plot
    plt.subplot(2, 2, 3)
    plt.scatter(gt_volumes, pred_volumes, alpha=0.7, s=50)
    min_vol, max_vol = min(min(gt_volumes), min(pred_volumes)), max(max(gt_volumes), max(pred_volumes))
    plt.plot([min_vol, max_vol], [min_vol, max_vol], 'r--', label='Perfect prediction')
    plt.xlabel("Ground Truth Volume (mmÂ³)")
    plt.ylabel("Predicted Volume (mmÂ³)")
    plt.title("Prediction vs Ground Truth")
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Histogram of errors
    plt.subplot(2, 2, 4)
    plt.hist(volume_diff_percent, bins=10, alpha=0.7, edgecolor='black')
    plt.xlabel("Error (%)")
    plt.ylabel("Frequency")
    plt.title("Error Distribution")
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"[INFO] Saved enhanced volume plot to {save_path}")

# =========================================================
# 6. Training Loop (with debug prints) - PAPER IMPLEMENTATION
# =========================================================
def train_inr_model(
    siren_model, frames, spatial_coords, temporal_coords,
    mesh_vertices, mesh_faces, voxel_spacing, mesh_scaler,
    num_epochs=1000, sample_points=10000,
    lambda_cycle=0.1, lambda_volume=0.0,
    device='cuda'
):
    print("=== è®ºæ–‡å®ç°ï¼šå›¾åƒé‡å»ºæŸå¤± + å‘¨æœŸä¸€è‡´æ€§ ===")
    siren_model = siren_model.to(device)
    optimizer = optim.Adam(siren_model.parameters(), lr=3e-5, weight_decay=1e-6)

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.8, patience=30
    )

    # Convert data
    spatial_coords_torch = torch.from_numpy(spatial_coords).float().to(device)
    frames_tensor = [torch.from_numpy(frame).float().to(device) for frame in frames]
    time_tensor = torch.from_numpy(temporal_coords).float().to(device)

    # Precompute GT volumes for final evaluation only
    gt_volumes = [compute_frame_volume_gt(f, voxel_spacing) for f in frames]
    print(f"[DEBUG] GT volume range: {min(gt_volumes):.1f}-{max(gt_volumes):.1f} mmÂ³")

    # ç¨³å®šçš„é‡‡æ ·ç­–ç•¥ï¼šå›ºå®šé‡‡æ ·æ¨¡å¼
    def sample_coordinates_stable(epoch, sample_points):
        """ç¨³å®šçš„é‡‡æ ·ç­–ç•¥ï¼šæ¯10ä¸ªepochæ‰è½»å¾®è°ƒæ•´é‡‡æ ·."""
        total_points = spatial_coords_torch.shape[0]
        if sample_points >= total_points:
            return torch.arange(total_points, device=device)
        
        # æ¯10ä¸ªepochæ‰å˜åŒ–ä¸€æ¬¡é‡‡æ ·ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§
        stable_seed = 42 + (epoch // 10)
        np.random.seed(stable_seed)
        indices = np.random.choice(total_points, sample_points, replace=False)
        return torch.from_numpy(indices).to(device)

    start_time = time.time()

    for epoch in range(num_epochs):
        optimizer.zero_grad()

        # Sample points using sklearn
        idx = sample_coordinates_stable(epoch, sample_points)
        sampled_coords = spatial_coords_torch[idx]

        if epoch in [0, 500, 999]:
            print(f"[DEBUG] Epoch {epoch} sampled coords (first 3): {sampled_coords[:3].cpu().numpy()}")

        # ===== è®ºæ–‡çš„æ ¸å¿ƒé‡å»ºæŸå¤±å®ç° =====
        # è®ºæ–‡å…¬å¼: min Î£ ||I_ti âˆ˜ Ï†_tiâ†’T - I_T||Â² + Î» R_cycle
        
        # è·å–å‚è€ƒå¸§ï¼ˆæœ€åä¸€å¸§ï¼‰
        reference_frame = frames_tensor[-1]  # I_T
        
        # è®¡ç®—æ‰€æœ‰å…¶ä»–å¸§åˆ°å‚è€ƒå¸§çš„å˜å½¢
        reconstruction_losses = []
        for t in range(len(frames) - 1):  # é™¤äº†æœ€åä¸€å¸§
            current_frame = frames_tensor[t]  # I_ti
            
            # è®¡ç®—å½“å‰æ—¶åˆ»åˆ°å‚è€ƒæ—¶åˆ»çš„å˜å½¢
            # Ï†_tiâ†’T = Ï†_T âˆ˜ Ï†_ti^(-1)
            # æˆ‘ä»¬éœ€è¦è®¡ç®—ä»å½“å‰æ—¶åˆ»åˆ°å‚è€ƒæ—¶åˆ»çš„å˜å½¢
            current_time = time_tensor[t]
            reference_time = time_tensor[-1]
            
            # è®¡ç®—å˜å½¢è½¨è¿¹ï¼šä»å½“å‰æ—¶åˆ»åˆ°å‚è€ƒæ—¶åˆ»
            time_points = torch.linspace(current_time, reference_time, 10, device=device)
            deformed_coords = integrate_velocity_to_deformation(siren_model, sampled_coords, time_points)
            
            # è·å–å˜å½¢åçš„åæ ‡ï¼ˆæœ€åä¸€å¸§çš„åæ ‡ï¼‰
            final_deformed_coords = deformed_coords[-1]
            
            # é‡‡æ ·å˜å½¢åçš„å›¾åƒå¼ºåº¦
            if epoch == 0 and t == 0:
                print(f"[DEBUG] Volume shape: {current_frame.shape}")
                print(f"[DEBUG] Coords shape: {final_deformed_coords.shape}")
                print(f"[DEBUG] Coords range: [{final_deformed_coords.min().item():.3f}, {final_deformed_coords.max().item():.3f}]")
            
            deformed_intensities = sample_intensity(current_frame, final_deformed_coords)
            reference_intensities = sample_intensity(reference_frame, final_deformed_coords)
            
            # é‡å»ºæŸå¤±ï¼š||I_ti âˆ˜ Ï†_tiâ†’T - I_T||Â²
            frame_recon_loss = torch.mean((deformed_intensities - reference_intensities) ** 2)
            reconstruction_losses.append(frame_recon_loss)
        
        # æ€»é‡å»ºæŸå¤±
        recon_loss = torch.mean(torch.stack(reconstruction_losses))

        # ===== å‘¨æœŸä¸€è‡´æ€§æŸå¤± =====
        # è®ºæ–‡å…¬å¼: R_cycle = (1/n) Î£ ||P_0,i - Ï†_T(P_0,i)||Â²
        
        # è®¡ç®—ä»èµ·å§‹æ—¶åˆ»åˆ°ç»“æŸæ—¶åˆ»çš„å®Œæ•´è½¨è¿¹
        full_trajectories = integrate_velocity_to_deformation(siren_model, sampled_coords, time_tensor)
        
        # èµ·å§‹ä½ç½®å’Œç»“æŸä½ç½®
        initial_positions = full_trajectories[0]
        final_positions = full_trajectories[-1]
        
        # å‘¨æœŸä¸€è‡´æ€§æŸå¤±
        cycle_loss = torch.mean((initial_positions - final_positions) ** 2)

        # ===== ç»„åˆæŸå¤± =====
        # è®ºæ–‡å…¬å¼: min [Î£ ||I_ti âˆ˜ Ï†_tiâ†’T - I_T||Â²] + Î» R_cycle
        total_loss = recon_loss + lambda_cycle * cycle_loss
        total_loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(siren_model.parameters(), max_norm=1.0)
        optimizer.step()

        # å­¦ä¹ ç‡è°ƒåº¦å™¨æ­¥è¿›
        scheduler.step(total_loss)

        # è¯¦ç»†çš„æŸå¤±ç›‘æ§
        if epoch % 10 == 0:
            current_lr = optimizer.param_groups[0]['lr']
            print(f"[Epoch {epoch:3d}] è®ºæ–‡å®ç° - Total={total_loss.item():.6f} "
                  f"Recon={recon_loss.item():.6f} Cycle={cycle_loss.item():.6f} "
                  f"LR={current_lr:.2e}")

        # æ—©åœæœºåˆ¶ï¼ˆå¯é€‰ï¼‰
        if epoch == 0:
            best_loss = total_loss.item()
            best_epoch = 0
        elif total_loss.item() < best_loss:
            best_loss = total_loss.item()
            best_epoch = epoch

    print(f"è®ºæ–‡å®ç°è®­ç»ƒå®Œæˆï¼Œç”¨æ—¶ {(time.time()-start_time)/60:.1f} åˆ†é’Ÿ")
    print(f"æœ€ä½³æŸå¤±: {best_loss:.4f} (epoch {best_epoch})")
    return siren_model, gt_volumes

# =========================================================
# 7. Main
# =========================================================
if __name__ == "__main__":
    data_path = "data/4007775_aneurysm/nnunet_outputs_pp"
    visualization_path = "data/4007775_aneurysm/visualizations"
    os.makedirs(visualization_path, exist_ok=True)

    # Load data
    dataset = CTSequenceDataset(data_path, num_frames=20)
    frames, temporal_coords = dataset.get_all_frames()
    spatial_coords = dataset.get_spatial_coords()
    voxel_spacing = dataset.get_voxel_spacing()

    # Extract initial mesh (0pct)
    initial_nifti_path = os.path.join(data_path, "0pct.nii.gz")
    nii = nib.load(initial_nifti_path)
    data = nii.get_fdata().astype(np.float32)
    mesh_vertices, mesh_faces, _, _ = measure.marching_cubes(data, level=0.5, spacing=voxel_spacing)

    # Use sklearn MinMaxScaler for mesh vertex normalization
    mesh_scaler = MinMaxScaler(feature_range=(-1, 1))
    mesh_vertices_norm = mesh_scaler.fit_transform(mesh_vertices)

    # Train model with fixed parameters
    siren_model = SIRENVelocityField(hidden_dim=256)
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    print("[INFO] ===== è®ºæ–‡å®ç°ç‰ˆæœ¬ =====")
    print("[INFO] è®ºæ–‡Title: Neural Fields for Continuous Periodic Motion Estimation in 4D Cardiovascular Imaging")
    print("[INFO] âœ… æ—¶é—´ç¼–ç : f(t) = (cos(2Ï€t), sin(2Ï€t)) - å·²æ­£ç¡®å®ç°")
    print("[INFO] âœ… SIRENç½‘ç»œ: ä½¿ç”¨æ­£å¼¦æ¿€æ´»å‡½æ•° - å·²æ­£ç¡®å®ç°") 
    print("[INFO] âœ… æŸå¤±å‡½æ•°: å›¾åƒé‡å»ºæŸå¤± + å‘¨æœŸä¸€è‡´æ€§ - è®ºæ–‡æ ¸å¿ƒæ–¹æ³•")
    print("[INFO] âœ… é‡å»ºæŸå¤±: ||I_ti âˆ˜ Ï†_tiâ†’T - I_T||Â² - ç›´æ¥ä¼˜åŒ–å›¾åƒåŒ¹é…")
    print("[INFO] âœ… ODEç§¯åˆ†: ä½¿ç”¨torchdiffeqè¿›è¡Œé€Ÿåº¦åœºç§¯åˆ†")
    print("[INFO] âœ… è®­ç»ƒç›®æ ‡: ä¼˜åŒ–å›¾åƒé‡å»ºè´¨é‡ï¼Œé—´æ¥æå‡ä½“ç§¯é¢„æµ‹å‡†ç¡®æ€§")
    print("[INFO] ğŸ¯ ç›®æ ‡: å®ç°è®ºæ–‡çš„æ ¸å¿ƒé‡å»ºæŸå¤±ï¼Œè§£å†³æŸå¤±å‡½æ•°ä¸è¯„ä¼°æŒ‡æ ‡ä¸åŒ¹é…é—®é¢˜")

    trained_model, gt_volumes = train_inr_model(
        siren_model, frames, spatial_coords, temporal_coords,
        mesh_vertices_norm, mesh_faces, voxel_spacing, mesh_scaler,
        num_epochs=500, sample_points=5300,  # è®ºæ–‡å®ç°è®­ç»ƒ
        lambda_cycle=0.01, lambda_volume=0.0,  # ä½¿ç”¨è®ºæ–‡çš„å‘¨æœŸæƒé‡
        device=device
    )

    # Predict volumes using sklearn scaler for inverse transform
    mesh_vertices_tensor = torch.from_numpy(mesh_vertices_norm).float().to(device)
    time_tensor = torch.from_numpy(temporal_coords).float().to(device)
    with torch.no_grad():
        mesh_trajectories = integrate_velocity_to_deformation(trained_model, mesh_vertices_tensor, time_tensor)

    pred_volumes = []
    for t in range(len(frames)):
        # Use sklearn scaler for inverse transform
        verts_norm = mesh_trajectories[t].cpu().numpy()
        verts_original = mesh_scaler.inverse_transform(verts_norm)
        
        # ä½¿ç”¨åŸå§‹åæ ‡è®¡ç®—ä½“ç§¯
        pred_volumes.append(compute_mesh_volume(verts_original, mesh_faces))

    # Plot + save with paper implementation
    vol_plot_path = os.path.join(visualization_path, "21volume_comparison_paper_implementation.png")
    plot_and_save_volumes(gt_volumes, pred_volumes, vol_plot_path)